{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7a4cef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C·∫•u h√¨nh ƒë∆∞·ªùng d·∫´n files:\n",
      "\n",
      "Amazon:\n",
      "  train: train_reviews_under80words.csv [‚úì]\n",
      "  dev: dev_reviews_under80words.csv [‚úì]\n",
      "  test: test_reviews_under80words.csv [‚úì]\n",
      "\n",
      "Hotels:\n",
      "  train: train_reviews_under80words.csv [‚úì]\n",
      "  dev: dev_reviews_under80words.csv [‚úì]\n",
      "  test: test_reviews_under80words.csv [‚úì]\n",
      "\n",
      "AmazonsElectronics:\n",
      "  all: neutral_output_aspect_filledNone.csv [‚úì]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n g·ªëc\n",
    "BASE_PATH = Path(\"H:/SentimentAnalystSchool/MidtermExam/DatasetUnder80kWord\")\n",
    "\n",
    "# ƒê·ªãnh nghƒ©a c√°c file c·∫ßn g·ªôp\n",
    "FILES_CONFIG = {\n",
    "    \"Amazon\": {\n",
    "        \"train\": BASE_PATH / \"Amazon\" / \"train_reviews_under80words.csv\",\n",
    "        \"dev\": BASE_PATH / \"Amazon\" / \"dev_reviews_under80words.csv\",\n",
    "        \"test\": BASE_PATH / \"Amazon\" / \"test_reviews_under80words.csv\"\n",
    "    },\n",
    "    \"Hotels\": {\n",
    "        \"train\": BASE_PATH / \"Hotels\" / \"train_reviews_under80words.csv\",\n",
    "        \"dev\": BASE_PATH / \"Hotels\" / \"dev_reviews_under80words.csv\",\n",
    "        \"test\": BASE_PATH / \"Hotels\" / \"test_reviews_under80words.csv\"\n",
    "    },\n",
    "    \"AmazonsElectronics\": {\n",
    "        \"all\": BASE_PATH / \"AmazonsElectronics\" / \"Kaggle\" / \"neutral_output_aspect_filledNone.csv\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"C·∫•u h√¨nh ƒë∆∞·ªùng d·∫´n files:\")\n",
    "for source, files in FILES_CONFIG.items():\n",
    "    print(f\"\\n{source}:\")\n",
    "    for file_type, path in files.items():\n",
    "        exists = \"‚úì\" if path.exists() else \"‚úó\"\n",
    "        print(f\"  {file_type}: {path.name} [{exists}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5acd404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H√†m load_and_standardize_data ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a!\n"
     ]
    }
   ],
   "source": [
    "def load_and_standardize_data(file_path):\n",
    "    \"\"\"\n",
    "    ƒê·ªçc file CSV v√† chu·∫©n h√≥a c·ªôt th√†nh reviewText, AspectTerm, Sentiment\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path: ƒë∆∞·ªùng d·∫´n file\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame ƒë√£ chu·∫©n h√≥a v·ªõi 3 c·ªôt: reviewText, AspectTerm, Sentiment\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Chu·∫©n h√≥a t√™n c·ªôt th√†nh ch·ªØ th∆∞·ªùng ƒë·ªÉ d·ªÖ x·ª≠ l√Ω\n",
    "        df.columns = df.columns.str.strip().str.lower()\n",
    "        \n",
    "        # Map c√°c t√™n c·ªôt c√≥ th·ªÉ kh√°c nhau v·ªÅ t√™n chu·∫©n\n",
    "        column_mapping = {\n",
    "            'reviewtext': 'reviewText',\n",
    "            'review': 'reviewText',\n",
    "            'text': 'reviewText',\n",
    "            'aspectterm': 'AspectTerm',\n",
    "            'aspect': 'AspectTerm',\n",
    "            'sentiment': 'Sentiment'\n",
    "        }\n",
    "        \n",
    "        df = df.rename(columns=column_mapping)\n",
    "        \n",
    "        # Ch·ªâ gi·ªØ 3 c·ªôt c·∫ßn thi·∫øt\n",
    "        required_cols = ['reviewText', 'AspectTerm', 'Sentiment']\n",
    "        available_cols = [col for col in required_cols if col in df.columns]\n",
    "        df = df[available_cols]\n",
    "        \n",
    "        # ƒêi·ªÅn 'None' v√†o c√°c AspectTerm tr·ªëng ho·∫∑c null\n",
    "        if 'AspectTerm' in df.columns:\n",
    "            # ƒê·∫øm s·ªë l∆∞·ª£ng tr∆∞·ªõc khi ƒëi·ªÅn\n",
    "            empty_mask = df['AspectTerm'].isna() | (df['AspectTerm'].astype(str).str.strip() == '')\n",
    "            empty_count = empty_mask.sum()\n",
    "            \n",
    "            # ƒêi·ªÅn 'None' v√†o c√°c √¥ tr·ªëng\n",
    "            df.loc[empty_mask, 'AspectTerm'] = 'No Aspect'\n",
    "            \n",
    "            print(f\"  ‚úì Loaded {len(df)} rows from {file_path.name} (filled {empty_count} empty AspectTerm with 'None')\")\n",
    "        else:\n",
    "            print(f\"  ‚úì Loaded {len(df)} rows from {file_path.name}\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚úó Error loading {file_path}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "print(\"H√†m load_and_standardize_data ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab62276e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H√†m merge_all_datasets ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a!\n"
     ]
    }
   ],
   "source": [
    "def merge_all_datasets(files_config, output_path=None, balance_config=None):\n",
    "    \"\"\"\n",
    "    G·ªôp t·∫•t c·∫£ c√°c dataset th√†nh m·ªôt file duy nh·∫•t\n",
    "    \n",
    "    Parameters:\n",
    "    - files_config: dict ch·ª©a c·∫•u h√¨nh c√°c file\n",
    "    - output_path: ƒë∆∞·ªùng d·∫´n l∆∞u file output (optional)\n",
    "    - balance_config: dict ƒë·ªÉ gi·ªõi h·∫°n s·ªë l∆∞·ª£ng m·∫´u theo sentiment (optional)\n",
    "                      V√≠ d·ª•: {'positive': 5000, 'negative': 5000, 'neutral': 5000}\n",
    "                      N·∫øu None, gi·ªØ nguy√™n t·∫•t c·∫£ d·ªØ li·ªáu\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame ƒë√£ g·ªôp v·ªõi 3 c·ªôt: reviewText, AspectTerm, Sentiment\n",
    "    \"\"\"\n",
    "    all_dataframes = []\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"B·∫ÆT ƒê·∫¶U G·ªòP DATASETS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for source_name, files in files_config.items():\n",
    "        print(f\"\\nüìÇ Loading from {source_name}:\")\n",
    "        for file_type, file_path in files.items():\n",
    "            if file_path.exists():\n",
    "                df = load_and_standardize_data(file_path)\n",
    "                if not df.empty:\n",
    "                    all_dataframes.append(df)\n",
    "            else:\n",
    "                print(f\"  ‚ö† File not found: {file_path}\")\n",
    "    \n",
    "    if not all_dataframes:\n",
    "        print(\"\\n‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu n√†o ƒë∆∞·ª£c load!\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # G·ªôp t·∫•t c·∫£\n",
    "    merged_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"K·∫æT QU·∫¢ G·ªòP DATASET (TR∆Ø·ªöC KHI C√ÇN B·∫∞NG)\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\nüìä T·ªïng s·ªë m·∫´u: {len(merged_df):,}\")\n",
    "    print(f\"\\nüìà Ph√¢n b·ªë theo Sentiment:\")\n",
    "    print(merged_df['Sentiment'].value_counts().to_string())\n",
    "    \n",
    "    # √Åp d·ª•ng balance_config n·∫øu c√≥\n",
    "    if balance_config:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"√ÅP D·ª§NG C√ÇN B·∫∞NG D·ªÆ LI·ªÜU\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        balanced_dfs = []\n",
    "        for sentiment, max_count in balance_config.items():\n",
    "            sentiment_df = merged_df[merged_df['Sentiment'].str.lower() == sentiment.lower()]\n",
    "            current_count = len(sentiment_df)\n",
    "            \n",
    "            if current_count > max_count:\n",
    "                sentiment_df = sentiment_df.sample(n=max_count, random_state=42)\n",
    "                print(f\"  {sentiment}: {current_count:,} ‚Üí {max_count:,} (gi·∫£m {current_count - max_count:,})\")\n",
    "            else:\n",
    "                print(f\"  {sentiment}: {current_count:,} (gi·ªØ nguy√™n, √≠t h∆°n {max_count:,})\")\n",
    "            \n",
    "            balanced_dfs.append(sentiment_df)\n",
    "        \n",
    "        merged_df = pd.concat(balanced_dfs, ignore_index=True)\n",
    "        merged_df = merged_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"K·∫æT QU·∫¢ CU·ªêI C√ôNG\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\nüìä T·ªïng s·ªë m·∫´u: {len(merged_df):,}\")\n",
    "    print(f\"\\nüìà Ph√¢n b·ªë theo Sentiment:\")\n",
    "    print(merged_df['Sentiment'].value_counts().to_string())\n",
    "    print(f\"\\nüìã C√°c c·ªôt: {list(merged_df.columns)}\")\n",
    "    \n",
    "    # L∆∞u file n·∫øu c√≥ output_path\n",
    "    if output_path:\n",
    "        merged_df.to_csv(output_path, index=False)\n",
    "        print(f\"\\nüíæ ƒê√£ l∆∞u file: {output_path}\")\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "print(\"H√†m merge_all_datasets ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "240f011c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "B·∫ÆT ƒê·∫¶U G·ªòP DATASETS\n",
      "============================================================\n",
      "\n",
      "üìÇ Loading from Amazon:\n",
      "  ‚úì Loaded 6297 rows from train_reviews_under80words.csv (filled 0 empty AspectTerm with 'None')\n",
      "  ‚úì Loaded 974 rows from dev_reviews_under80words.csv (filled 0 empty AspectTerm with 'None')\n",
      "  ‚úì Loaded 966 rows from test_reviews_under80words.csv (filled 0 empty AspectTerm with 'None')\n",
      "\n",
      "üìÇ Loading from Hotels:\n",
      "  ‚úì Loaded 10126 rows from train_reviews_under80words.csv (filled 0 empty AspectTerm with 'None')\n",
      "  ‚úì Loaded 1036 rows from dev_reviews_under80words.csv (filled 0 empty AspectTerm with 'None')\n",
      "  ‚úì Loaded 242 rows from test_reviews_under80words.csv (filled 0 empty AspectTerm with 'None')\n",
      "\n",
      "üìÇ Loading from AmazonsElectronics:\n",
      "  ‚úì Loaded 5000 rows from neutral_output_aspect_filledNone.csv (filled 3788 empty AspectTerm with 'None')\n",
      "\n",
      "============================================================\n",
      "K·∫æT QU·∫¢ G·ªòP DATASET (TR∆Ø·ªöC KHI C√ÇN B·∫∞NG)\n",
      "============================================================\n",
      "\n",
      "üìä T·ªïng s·ªë m·∫´u: 24,641\n",
      "\n",
      "üìà Ph√¢n b·ªë theo Sentiment:\n",
      "Sentiment\n",
      "positive    15937\n",
      "neutral      5576\n",
      "negative     3116\n",
      "\n",
      "============================================================\n",
      "√ÅP D·ª§NG C√ÇN B·∫∞NG D·ªÆ LI·ªÜU\n",
      "============================================================\n",
      "  positive: 15,937 ‚Üí 6,600 (gi·∫£m 9,337)\n",
      "  negative: 3,116 (gi·ªØ nguy√™n, √≠t h∆°n 6,600)\n",
      "  neutral: 5,576 ‚Üí 5,000 (gi·∫£m 576)\n",
      "\n",
      "============================================================\n",
      "K·∫æT QU·∫¢ CU·ªêI C√ôNG\n",
      "============================================================\n",
      "\n",
      "üìä T·ªïng s·ªë m·∫´u: 14,716\n",
      "\n",
      "üìà Ph√¢n b·ªë theo Sentiment:\n",
      "Sentiment\n",
      "positive    6600\n",
      "neutral     5000\n",
      "negative    3116\n",
      "\n",
      "üìã C√°c c·ªôt: ['reviewText', 'AspectTerm', 'Sentiment']\n",
      "\n",
      "üíæ ƒê√£ l∆∞u file: H:\\SentimentAnalystSchool\\MidtermExam\\DatasetUnder80kWord\\merged_dataset_all_13200rows.csv\n",
      "  ‚úì Loaded 5000 rows from neutral_output_aspect_filledNone.csv (filled 3788 empty AspectTerm with 'None')\n",
      "\n",
      "============================================================\n",
      "K·∫æT QU·∫¢ G·ªòP DATASET (TR∆Ø·ªöC KHI C√ÇN B·∫∞NG)\n",
      "============================================================\n",
      "\n",
      "üìä T·ªïng s·ªë m·∫´u: 24,641\n",
      "\n",
      "üìà Ph√¢n b·ªë theo Sentiment:\n",
      "Sentiment\n",
      "positive    15937\n",
      "neutral      5576\n",
      "negative     3116\n",
      "\n",
      "============================================================\n",
      "√ÅP D·ª§NG C√ÇN B·∫∞NG D·ªÆ LI·ªÜU\n",
      "============================================================\n",
      "  positive: 15,937 ‚Üí 6,600 (gi·∫£m 9,337)\n",
      "  negative: 3,116 (gi·ªØ nguy√™n, √≠t h∆°n 6,600)\n",
      "  neutral: 5,576 ‚Üí 5,000 (gi·∫£m 576)\n",
      "\n",
      "============================================================\n",
      "K·∫æT QU·∫¢ CU·ªêI C√ôNG\n",
      "============================================================\n",
      "\n",
      "üìä T·ªïng s·ªë m·∫´u: 14,716\n",
      "\n",
      "üìà Ph√¢n b·ªë theo Sentiment:\n",
      "Sentiment\n",
      "positive    6600\n",
      "neutral     5000\n",
      "negative    3116\n",
      "\n",
      "üìã C√°c c·ªôt: ['reviewText', 'AspectTerm', 'Sentiment']\n",
      "\n",
      "üíæ ƒê√£ l∆∞u file: H:\\SentimentAnalystSchool\\MidtermExam\\DatasetUnder80kWord\\merged_dataset_all_13200rows.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# C·∫§U H√åNH S·ªê L∆Ø·ª¢NG M·∫™U THEO SENTIMENT\n",
    "# ============================================\n",
    "# Ch·ªânh s·ª≠a c√°c gi√° tr·ªã b√™n d∆∞·ªõi ƒë·ªÉ thay ƒë·ªïi s·ªë l∆∞·ª£ng m·∫´u cho m·ªói nh√£n\n",
    "# ƒê·∫∑t None n·∫øu mu·ªën gi·ªØ t·∫•t c·∫£ d·ªØ li·ªáu kh√¥ng gi·ªõi h·∫°n\n",
    "\n",
    "BALANCE_CONFIG = {\n",
    "    'positive': 6600,   # S·ªë l∆∞·ª£ng m·∫´u positive t·ªëi ƒëa\n",
    "    'negative': 6600,   # S·ªë l∆∞·ª£ng m·∫´u negative t·ªëi ƒëa  \n",
    "    'neutral': 5000    # S·ªë l∆∞·ª£ng m·∫´u neutral t·ªëi ƒëa\n",
    "}\n",
    "\n",
    "# ƒê·∫∑t BALANCE_CONFIG = None n·∫øu mu·ªën gi·ªØ t·∫•t c·∫£ d·ªØ li·ªáu\n",
    "# BALANCE_CONFIG = None\n",
    "\n",
    "# ============================================\n",
    "# Th·ª±c hi·ªán g·ªôp dataset\n",
    "OUTPUT_PATH = BASE_PATH / \"merged_dataset_all_13200rows.csv\"\n",
    "\n",
    "merged_df = merge_all_datasets(\n",
    "    FILES_CONFIG, \n",
    "    output_path=OUTPUT_PATH,\n",
    "    balance_config=BALANCE_CONFIG\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f236f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã M·ªôt s·ªë m·∫´u d·ªØ li·ªáu ƒë·∫ßu ti√™n:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>AspectTerm</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have seen and purchased these at lower price...</td>\n",
       "      <td>No Aspect</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I was thinking about other thing, it was very ...</td>\n",
       "      <td>No Aspect</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>There are Better Options than this tired , out...</td>\n",
       "      <td>hotel quality</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I think is good, but I think creative labs pro...</td>\n",
       "      <td>No Aspect</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is NOT an Apple product. Although, it is ...</td>\n",
       "      <td>No Aspect</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Basically , you end up paying well over 2 time...</td>\n",
       "      <td>food prices</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>There ' s no bitter after taste , and it ' s g...</td>\n",
       "      <td>food quality</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I like the fact that there are no additives , ...</td>\n",
       "      <td>food quality</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Restaurant very odd .</td>\n",
       "      <td>facilities general</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Appears to do the trick for being able to char...</td>\n",
       "      <td>price</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText          AspectTerm  \\\n",
       "0  I have seen and purchased these at lower price...           No Aspect   \n",
       "1  I was thinking about other thing, it was very ...           No Aspect   \n",
       "2  There are Better Options than this tired , out...       hotel quality   \n",
       "3  I think is good, but I think creative labs pro...           No Aspect   \n",
       "4  This is NOT an Apple product. Although, it is ...           No Aspect   \n",
       "5  Basically , you end up paying well over 2 time...         food prices   \n",
       "6  There ' s no bitter after taste , and it ' s g...        food quality   \n",
       "7  I like the fact that there are no additives , ...        food quality   \n",
       "8                              Restaurant very odd .  facilities general   \n",
       "9  Appears to do the trick for being able to char...               price   \n",
       "\n",
       "  Sentiment  \n",
       "0   neutral  \n",
       "1   neutral  \n",
       "2  negative  \n",
       "3   neutral  \n",
       "4   neutral  \n",
       "5  negative  \n",
       "6  positive  \n",
       "7  positive  \n",
       "8  negative  \n",
       "9   neutral  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Xem m·ªôt s·ªë m·∫´u d·ªØ li·ªáu\n",
    "print(\"üìã M·ªôt s·ªë m·∫´u d·ªØ li·ªáu ƒë·∫ßu ti√™n:\")\n",
    "merged_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86322249",
   "metadata": {},
   "source": [
    "## T·ªïng k·∫øt\n",
    "\n",
    "File ƒë√£ ƒë∆∞·ª£c t·∫°o v·ªõi c·∫•u tr√∫c 3 c·ªôt:\n",
    "- `reviewText`: N·ªôi dung review\n",
    "- `AspectTerm`: Aspect term ƒë∆∞·ª£c tr√≠ch xu·∫•t\n",
    "- `Sentiment`: Nh√£n sentiment (positive/negative/neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ea78927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "G·ªòP DATASET: merged_dataset + semeval_train\n",
      "============================================================\n",
      "\n",
      "üìÇ Dataset 1: merged_dataset_all_13200rows.csv\n",
      "   S·ªë d√≤ng: 14,716\n",
      "   C√°c c·ªôt: ['reviewText', 'AspectTerm', 'Sentiment']\n",
      "   Ph√¢n b·ªë Sentiment:\n",
      "Sentiment\n",
      "positive    6600\n",
      "neutral     5000\n",
      "negative    3116\n",
      "\n",
      "üìÇ Dataset 2: semeval_train.csv\n",
      "   S·ªë d√≤ng: 5,416\n",
      "   C√°c c·ªôt: ['reviewText', 'Sentiment', 'AspectTerm']\n",
      "   Ph√¢n b·ªë Sentiment:\n",
      "Sentiment\n",
      "positive    3294\n",
      "negative    1833\n",
      "neutral      289\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# G·ªòP 2 DATASET: merged_dataset + semeval_train\n",
    "# ============================================\n",
    "print(\"=\" * 60)\n",
    "print(\"G·ªòP DATASET: merged_dataset + semeval_train\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n c√°c file\n",
    "MERGED_PATH = Path(\"H:/SentimentAnalystSchool/MidtermExam/DatasetUnder80kWord/merged_dataset_all_13200rows.csv\")\n",
    "SEMEVAL_PATH = Path(\"H:/SentimentAnalystSchool/MidtermExam/Semeval/semeval_train.csv\")\n",
    "\n",
    "# ƒê·ªçc 2 file\n",
    "df_merged = pd.read_csv(MERGED_PATH)\n",
    "df_semeval = pd.read_csv(SEMEVAL_PATH)\n",
    "\n",
    "print(f\"\\nüìÇ Dataset 1: merged_dataset_all_13200rows.csv\")\n",
    "print(f\"   S·ªë d√≤ng: {len(df_merged):,}\")\n",
    "print(f\"   C√°c c·ªôt: {list(df_merged.columns)}\")\n",
    "print(f\"   Ph√¢n b·ªë Sentiment:\")\n",
    "print(df_merged['Sentiment'].value_counts().to_string())\n",
    "\n",
    "print(f\"\\nüìÇ Dataset 2: semeval_train.csv\")\n",
    "print(f\"   S·ªë d√≤ng: {len(df_semeval):,}\")\n",
    "print(f\"   C√°c c·ªôt: {list(df_semeval.columns)}\")\n",
    "print(f\"   Ph√¢n b·ªë Sentiment:\")\n",
    "print(df_semeval['Sentiment'].value_counts().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2f63d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "K·∫æT QU·∫¢ G·ªòP 2 DATASET\n",
      "============================================================\n",
      "\n",
      "üìä T·ªïng s·ªë m·∫´u: 20,132\n",
      "   - T·ª´ merged_dataset: 14,716\n",
      "   - T·ª´ semeval_train: 5,416\n",
      "\n",
      "üìà Ph√¢n b·ªë Sentiment sau khi g·ªôp:\n",
      "Sentiment\n",
      "positive    9894\n",
      "neutral     5289\n",
      "negative    4949\n",
      "\n",
      "üìã C√°c c·ªôt: ['reviewText', 'AspectTerm', 'Sentiment']\n"
     ]
    }
   ],
   "source": [
    "# Chu·∫©n h√≥a t√™n c·ªôt c·ªßa semeval_train ƒë·ªÉ kh·ªõp v·ªõi merged_dataset\n",
    "# semeval_train c√≥: reviewText, Sentiment, AspectTerms\n",
    "# merged_dataset c√≥: reviewText, AspectTerm, Sentiment\n",
    "\n",
    "# Rename c·ªôt AspectTerms -> AspectTerm (b·ªè s)\n",
    "if 'AspectTerms' in df_semeval.columns:\n",
    "    df_semeval = df_semeval.rename(columns={'AspectTerms': 'AspectTerm'})\n",
    "    print(\"‚úì ƒê√£ ƒë·ªïi t√™n c·ªôt 'AspectTerms' -> 'AspectTerm'\")\n",
    "\n",
    "# S·∫Øp x·∫øp l·∫°i th·ª© t·ª± c·ªôt cho kh·ªõp\n",
    "df_semeval = df_semeval[['reviewText', 'AspectTerm', 'Sentiment']]\n",
    "\n",
    "# G·ªôp 2 dataset\n",
    "df_combined = pd.concat([df_merged, df_semeval], ignore_index=True)\n",
    "\n",
    "# Shuffle d·ªØ li·ªáu\n",
    "df_combined = df_combined.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"K·∫æT QU·∫¢ G·ªòP 2 DATASET\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nüìä T·ªïng s·ªë m·∫´u: {len(df_combined):,}\")\n",
    "print(f\"   - T·ª´ merged_dataset: {len(df_merged):,}\")\n",
    "print(f\"   - T·ª´ semeval_train: {len(df_semeval):,}\")\n",
    "\n",
    "print(f\"\\nüìà Ph√¢n b·ªë Sentiment sau khi g·ªôp:\")\n",
    "print(df_combined['Sentiment'].value_counts().to_string())\n",
    "\n",
    "print(f\"\\nüìã C√°c c·ªôt: {list(df_combined.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f616200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "√ÅP D·ª§NG C√ÇN B·∫∞NG D·ªÆ LI·ªÜU\n",
      "============================================================\n",
      "  positive: 9,894 (gi·ªØ nguy√™n)\n",
      "  negative: 4,949 (gi·ªØ nguy√™n)\n",
      "  neutral: 5,289 ‚Üí 5,000 (gi·∫£m 289)\n",
      "\n",
      "üìä T·ªïng s·ªë m·∫´u cu·ªëi c√πng: 19,843\n",
      "\n",
      "üìà Ph√¢n b·ªë Sentiment cu·ªëi c√πng:\n",
      "Sentiment\n",
      "positive    9894\n",
      "neutral     5000\n",
      "negative    4949\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# C√ÇN B·∫∞NG D·ªÆ LI·ªÜU (T√ôY CH·ªåN)\n",
    "# ============================================\n",
    "# Ch·ªânh s·ª≠a config b√™n d∆∞·ªõi n·∫øu mu·ªën c√¢n b·∫±ng\n",
    "\n",
    "BALANCE_COMBINED = {\n",
    "    'positive': 10000,   # S·ªë l∆∞·ª£ng m·∫´u positive t·ªëi ƒëa\n",
    "    'negative': 10000,   # S·ªë l∆∞·ª£ng m·∫´u negative t·ªëi ƒëa  \n",
    "    'neutral': 5000      # S·ªë l∆∞·ª£ng m·∫´u neutral t·ªëi ƒëa\n",
    "}\n",
    "\n",
    "# ƒê·∫∑t BALANCE_COMBINED = None n·∫øu kh√¥ng mu·ªën c√¢n b·∫±ng\n",
    "# BALANCE_COMBINED = None\n",
    "\n",
    "if BALANCE_COMBINED:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"√ÅP D·ª§NG C√ÇN B·∫∞NG D·ªÆ LI·ªÜU\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    balanced_dfs = []\n",
    "    for sentiment, max_count in BALANCE_COMBINED.items():\n",
    "        sentiment_df = df_combined[df_combined['Sentiment'].str.lower() == sentiment.lower()]\n",
    "        current_count = len(sentiment_df)\n",
    "        \n",
    "        if current_count > max_count:\n",
    "            sentiment_df = sentiment_df.sample(n=max_count, random_state=42)\n",
    "            print(f\"  {sentiment}: {current_count:,} ‚Üí {max_count:,} (gi·∫£m {current_count - max_count:,})\")\n",
    "        else:\n",
    "            print(f\"  {sentiment}: {current_count:,} (gi·ªØ nguy√™n)\")\n",
    "        \n",
    "        balanced_dfs.append(sentiment_df)\n",
    "    \n",
    "    df_final = pd.concat(balanced_dfs, ignore_index=True)\n",
    "    df_final = df_final.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "else:\n",
    "    df_final = df_combined\n",
    "\n",
    "print(f\"\\nüìä T·ªïng s·ªë m·∫´u cu·ªëi c√πng: {len(df_final):,}\")\n",
    "print(f\"\\nüìà Ph√¢n b·ªë Sentiment cu·ªëi c√πng:\")\n",
    "print(df_final['Sentiment'].value_counts().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "678d74b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ l∆∞u file g·ªôp: H:\\SentimentAnalystSchool\\MidtermExam\\DatasetUnder80kWord\\merged_dataset_combined_semeval.csv\n",
      "   T·ªïng s·ªë d√≤ng: 19,843\n",
      "\n",
      "üìã M·∫´u d·ªØ li·ªáu (10 d√≤ng ƒë·∫ßu):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>AspectTerm</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That made me really sad because I really wante...</td>\n",
       "      <td>food general</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The friction pad is good to use in your car.  ...</td>\n",
       "      <td>No Aspect</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I wasn ' t sure how I would like the smoked ho...</td>\n",
       "      <td>food general</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I ordered these thinking they were something d...</td>\n",
       "      <td>No Aspect</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There are a ton of hotels and I say , look els...</td>\n",
       "      <td>hotel miscellaneous</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Key Word = Budget Monte Carlo is clean , fairl...</td>\n",
       "      <td>location general</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The ambience was nice, but service wasn't so g...</td>\n",
       "      <td>SERVICE-GENERAL</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Excellent value ( at London prices ) for a lux...</td>\n",
       "      <td>hotel prices</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>We enjoyed eating at Ginger and Olsen - two ne...</td>\n",
       "      <td>service general</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Room was very comfortable and modern , and goo...</td>\n",
       "      <td>rooms design_features</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText             AspectTerm  \\\n",
       "0  That made me really sad because I really wante...           food general   \n",
       "1  The friction pad is good to use in your car.  ...              No Aspect   \n",
       "2  I wasn ' t sure how I would like the smoked ho...           food general   \n",
       "3  I ordered these thinking they were something d...              No Aspect   \n",
       "4  There are a ton of hotels and I say , look els...    hotel miscellaneous   \n",
       "5  Key Word = Budget Monte Carlo is clean , fairl...       location general   \n",
       "6  The ambience was nice, but service wasn't so g...        SERVICE-GENERAL   \n",
       "7  Excellent value ( at London prices ) for a lux...           hotel prices   \n",
       "8  We enjoyed eating at Ginger and Olsen - two ne...        service general   \n",
       "9  Room was very comfortable and modern , and goo...  rooms design_features   \n",
       "\n",
       "  Sentiment  \n",
       "0  negative  \n",
       "1   neutral  \n",
       "2  positive  \n",
       "3   neutral  \n",
       "4  negative  \n",
       "5  positive  \n",
       "6  negative  \n",
       "7  positive  \n",
       "8  positive  \n",
       "9  positive  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L∆∞u file g·ªôp\n",
    "OUTPUT_COMBINED_PATH = Path(\"H:/SentimentAnalystSchool/MidtermExam/DatasetUnder80kWord/merged_dataset_combined_semeval.csv\")\n",
    "df_final.to_csv(OUTPUT_COMBINED_PATH, index=False)\n",
    "\n",
    "print(f\"‚úÖ ƒê√£ l∆∞u file g·ªôp: {OUTPUT_COMBINED_PATH}\")\n",
    "print(f\"   T·ªïng s·ªë d√≤ng: {len(df_final):,}\")\n",
    "\n",
    "# Xem m·∫´u d·ªØ li·ªáu\n",
    "print(\"\\nüìã M·∫´u d·ªØ li·ªáu (10 d√≤ng ƒë·∫ßu):\")\n",
    "df_final.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ba1ac0",
   "metadata": {},
   "source": [
    "# G·ªôp merged_dataset_combined_semeval.csv + df_train_all_new.csv\n",
    "\n",
    "G·ªôp 2 file dataset v·ªõi ƒë·ªãnh d·∫°ng chu·∫©n `reviewText, AspectTerm, Sentiment`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab3f629a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì H√†m standardize_columns() ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a!\n",
      "  H·ªó tr·ª£ c√°c format:\n",
      "  - reviewText, AspectTerm, Sentiment\n",
      "  - text, aspect, polarity (SemEval)\n",
      "  - domain, review_id, sentence_id, text, aspect, polarity, label\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def standardize_columns(df):\n",
    "    \"\"\"\n",
    "    Chu·∫©n h√≥a t√™n c·ªôt c·ªßa DataFrame th√†nh format chu·∫©n: reviewText, AspectTerm, Sentiment\n",
    "    \n",
    "    H·ªó tr·ª£ c√°c format input:\n",
    "    - Format 1: reviewText, AspectTerm, Sentiment (ƒë√£ chu·∫©n)\n",
    "    - Format 2: text, aspect, polarity (SemEval format)\n",
    "    - Format 3: domain, review_id, sentence_id, text, aspect, polarity, label\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame c·∫ßn chu·∫©n h√≥a\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame ƒë√£ chu·∫©n h√≥a v·ªõi 3 c·ªôt: reviewText, AspectTerm, Sentiment\n",
    "    \"\"\"\n",
    "    # T·∫°o copy ƒë·ªÉ kh√¥ng ·∫£nh h∆∞·ªüng df g·ªëc\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Chu·∫©n h√≥a t√™n c·ªôt th√†nh ch·ªØ th∆∞·ªùng ƒë·ªÉ d·ªÖ x·ª≠ l√Ω\n",
    "    df.columns = df.columns.str.strip().str.lower()\n",
    "    \n",
    "    # Map c√°c t√™n c·ªôt c√≥ th·ªÉ kh√°c nhau v·ªÅ t√™n chu·∫©n\n",
    "    column_mapping = {\n",
    "        # reviewText\n",
    "        'reviewtext': 'reviewText',\n",
    "        'review': 'reviewText',\n",
    "        'text': 'reviewText',\n",
    "        'sentence': 'reviewText',\n",
    "        'content': 'reviewText',\n",
    "        # AspectTerm  \n",
    "        'aspectterm': 'AspectTerm',\n",
    "        'aspectterms': 'AspectTerm',\n",
    "        'aspect': 'AspectTerm',\n",
    "        'aspect_term': 'AspectTerm',\n",
    "        # Sentiment\n",
    "        'sentiment': 'Sentiment',\n",
    "        'polarity': 'Sentiment',\n",
    "        'label': 'Sentiment'  # N·∫øu kh√¥ng c√≥ polarity th√¨ d√πng label\n",
    "    }\n",
    "    \n",
    "    # ∆Øu ti√™n polarity h∆°n label n·∫øu c·∫£ 2 ƒë·ªÅu c√≥\n",
    "    if 'polarity' in df.columns and 'label' in df.columns:\n",
    "        # Gi·ªØ polarity, b·ªè qua label trong mapping\n",
    "        df = df.rename(columns={'polarity': 'Sentiment', 'text': 'reviewText', 'aspect': 'AspectTerm'})\n",
    "    else:\n",
    "        df = df.rename(columns=column_mapping)\n",
    "    \n",
    "    # Ch·ªâ gi·ªØ 3 c·ªôt c·∫ßn thi·∫øt\n",
    "    required_cols = ['reviewText', 'AspectTerm', 'Sentiment']\n",
    "    available_cols = [col for col in required_cols if col in df.columns]\n",
    "    \n",
    "    if len(available_cols) < 3:\n",
    "        missing = set(required_cols) - set(available_cols)\n",
    "        print(f\"  ‚ö† Thi·∫øu c√°c c·ªôt: {missing}\")\n",
    "        print(f\"  üìã C√°c c·ªôt hi·ªán c√≥: {list(df.columns)}\")\n",
    "    \n",
    "    df = df[available_cols]\n",
    "    \n",
    "    # ƒêi·ªÅn 'No Aspect' v√†o c√°c AspectTerm tr·ªëng ho·∫∑c null\n",
    "    if 'AspectTerm' in df.columns:\n",
    "        empty_mask = df['AspectTerm'].isna() | (df['AspectTerm'].astype(str).str.strip() == '')\n",
    "        empty_count = empty_mask.sum()\n",
    "        df.loc[empty_mask, 'AspectTerm'] = 'No Aspect'\n",
    "        if empty_count > 0:\n",
    "            print(f\"  ‚úì ƒê√£ ƒëi·ªÅn {empty_count} AspectTerm tr·ªëng v·ªõi 'No Aspect'\")\n",
    "        \n",
    "        # Chuy·ªÉn # th√†nh - trong AspectTerm (LAPTOP#GENERAL -> LAPTOP-GENERAL)\n",
    "        df['AspectTerm'] = df['AspectTerm'].astype(str).str.replace('#', '-', regex=False)\n",
    "    \n",
    "    # Chu·∫©n h√≥a Sentiment v·ªÅ lowercase\n",
    "    if 'Sentiment' in df.columns:\n",
    "        df['Sentiment'] = df['Sentiment'].astype(str).str.strip().str.lower()\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"‚úì H√†m standardize_columns() ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a!\")\n",
    "print(\"  H·ªó tr·ª£ c√°c format:\")\n",
    "print(\"  - reviewText, AspectTerm, Sentiment\")\n",
    "print(\"  - text, aspect, polarity (SemEval)\")\n",
    "print(\"  - domain, review_id, sentence_id, text, aspect, polarity, label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e61aafb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "G·ªòP DATASET: merged_dataset_combined_semeval + df_train_all_new\n",
      "============================================================\n",
      "\n",
      "üìÇ Dataset 1: merged_dataset_all_NoAspect_version.csv\n",
      "   C·ªôt ban ƒë·∫ßu: ['reviewText', 'AspectTerm', 'Sentiment']\n",
      "   S·ªë d√≤ng: 14,716\n",
      "   C·ªôt sau chu·∫©n h√≥a: ['reviewText', 'AspectTerm', 'Sentiment']\n",
      "   Ph√¢n b·ªë Sentiment:\n",
      "Sentiment\n",
      "positive    6600\n",
      "neutral     5000\n",
      "negative    3116\n",
      "\n",
      "üìÇ Dataset 2: df_train_all_new.csv\n",
      "   C·ªôt ban ƒë·∫ßu: ['domain', 'review_id', 'sentence_id', 'text', 'aspect', 'polarity', 'label']\n",
      "   S·ªë d√≤ng: 5,705\n",
      "   C·ªôt sau chu·∫©n h√≥a: ['reviewText', 'AspectTerm', 'Sentiment']\n",
      "   Ph√¢n b·ªë Sentiment:\n",
      "Sentiment\n",
      "positive    3294\n",
      "negative    1833\n",
      "neutral      578\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# G·ªòP: merged_dataset_combined_semeval + df_train_all_new\n",
    "# ============================================\n",
    "print(\"=\" * 60)\n",
    "print(\"G·ªòP DATASET: merged_dataset_combined_semeval + df_train_all_new\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n c√°c file\n",
    "MERGED_COMBINED_PATH = Path(\"H:/SentimentAnalystSchool/MidtermExam/DatasetUnder80kWord/merged_dataset_all_NoAspect_version.csv\")\n",
    "SEMEVAL_NEW_PATH = Path(\"H:/SentimentAnalystSchool/MidtermExam/Semeval/df_train_all_new.csv\")\n",
    "\n",
    "# ƒê·ªçc 2 file\n",
    "df_merged_combined = pd.read_csv(MERGED_COMBINED_PATH)\n",
    "df_semeval_new = pd.read_csv(SEMEVAL_NEW_PATH)\n",
    "\n",
    "# Chu·∫©n h√≥a c·ªôt cho c·∫£ 2 dataset\n",
    "print(\"\\nüìÇ Dataset 1: merged_dataset_all_NoAspect_version.csv\")\n",
    "print(f\"   C·ªôt ban ƒë·∫ßu: {list(df_merged_combined.columns)}\")\n",
    "df_merged_combined = standardize_columns(df_merged_combined)\n",
    "print(f\"   S·ªë d√≤ng: {len(df_merged_combined):,}\")\n",
    "print(f\"   C·ªôt sau chu·∫©n h√≥a: {list(df_merged_combined.columns)}\")\n",
    "print(f\"   Ph√¢n b·ªë Sentiment:\")\n",
    "print(df_merged_combined['Sentiment'].value_counts().to_string())\n",
    "\n",
    "print(f\"\\nüìÇ Dataset 2: df_train_all_new.csv\")\n",
    "print(f\"   C·ªôt ban ƒë·∫ßu: {list(df_semeval_new.columns)}\")\n",
    "df_semeval_new = standardize_columns(df_semeval_new)\n",
    "print(f\"   S·ªë d√≤ng: {len(df_semeval_new):,}\")\n",
    "print(f\"   C·ªôt sau chu·∫©n h√≥a: {list(df_semeval_new.columns)}\")\n",
    "print(f\"   Ph√¢n b·ªë Sentiment:\")\n",
    "print(df_semeval_new['Sentiment'].value_counts().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "babb0f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "K·∫æT QU·∫¢ G·ªòP 2 DATASET\n",
      "============================================================\n",
      "\n",
      "üìä T·ªïng s·ªë m·∫´u: 20,421\n",
      "   - T·ª´ merged_dataset_combined_semeval: 14,716\n",
      "   - T·ª´ semeval_train_new: 5,705\n",
      "\n",
      "üìà Ph√¢n b·ªë Sentiment sau khi g·ªôp:\n",
      "Sentiment\n",
      "positive    9894\n",
      "neutral     5578\n",
      "negative    4949\n",
      "\n",
      "üìã C√°c c·ªôt: ['reviewText', 'AspectTerm', 'Sentiment']\n"
     ]
    }
   ],
   "source": [
    "# G·ªôp 2 dataset\n",
    "# C·∫£ 2 file ƒë·ªÅu c√≥ c√πng format: reviewText, AspectTerm, Sentiment\n",
    "df_all_combined = pd.concat([df_merged_combined, df_semeval_new], ignore_index=True)\n",
    "\n",
    "# Shuffle d·ªØ li·ªáu\n",
    "df_all_combined = df_all_combined.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"K·∫æT QU·∫¢ G·ªòP 2 DATASET\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nüìä T·ªïng s·ªë m·∫´u: {len(df_all_combined):,}\")\n",
    "print(f\"   - T·ª´ merged_dataset_combined_semeval: {len(df_merged_combined):,}\")\n",
    "print(f\"   - T·ª´ semeval_train_new: {len(df_semeval_new):,}\")\n",
    "\n",
    "print(f\"\\nüìà Ph√¢n b·ªë Sentiment sau khi g·ªôp:\")\n",
    "print(df_all_combined['Sentiment'].value_counts().to_string())\n",
    "\n",
    "print(f\"\\nüìã C√°c c·ªôt: {list(df_all_combined.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc861d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ l∆∞u file g·ªôp: H:\\SentimentAnalystSchool\\MidtermExam\\DatasetUnder80kWord\\merged_all_final.csv\n",
      "   T·ªïng s·ªë d√≤ng: 20,421\n",
      "\n",
      "üìã M·∫´u d·ªØ li·ªáu (10 d√≤ng ƒë·∫ßu):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>AspectTerm</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bigger screen than expected, laptop with a des...</td>\n",
       "      <td>DISPLAY-DESIGN_FEATURES</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The hotel staff when we stayed there were extr...</td>\n",
       "      <td>hotel design_features</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The main tourist spots are within a twenty min...</td>\n",
       "      <td>location general</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Never buy from Lake Champlain .</td>\n",
       "      <td>food recommendation</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It had most of the features and all of the pow...</td>\n",
       "      <td>LAPTOP-OPERATION_PERFORMANCE</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I complained that this did not constitute an o...</td>\n",
       "      <td>service general</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Took it back as it was defective.</td>\n",
       "      <td>LAPTOP-QUALITY</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Even better than the photos ! In addition to a...</td>\n",
       "      <td>hotel design_features</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Works fine for charging (no data connection). ...</td>\n",
       "      <td>No Aspect</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I bought them because of Hungry Girl ' s glowi...</td>\n",
       "      <td>food general</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  \\\n",
       "0  Bigger screen than expected, laptop with a des...   \n",
       "1  The hotel staff when we stayed there were extr...   \n",
       "2  The main tourist spots are within a twenty min...   \n",
       "3                    Never buy from Lake Champlain .   \n",
       "4  It had most of the features and all of the pow...   \n",
       "5  I complained that this did not constitute an o...   \n",
       "6                  Took it back as it was defective.   \n",
       "7  Even better than the photos ! In addition to a...   \n",
       "8  Works fine for charging (no data connection). ...   \n",
       "9  I bought them because of Hungry Girl ' s glowi...   \n",
       "\n",
       "                     AspectTerm Sentiment  \n",
       "0       DISPLAY-DESIGN_FEATURES  positive  \n",
       "1         hotel design_features  negative  \n",
       "2              location general  positive  \n",
       "3           food recommendation  negative  \n",
       "4  LAPTOP-OPERATION_PERFORMANCE  positive  \n",
       "5               service general  negative  \n",
       "6                LAPTOP-QUALITY  negative  \n",
       "7         hotel design_features  positive  \n",
       "8                     No Aspect   neutral  \n",
       "9                  food general  negative  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L∆∞u file g·ªôp cu·ªëi c√πng\n",
    "OUTPUT_ALL_PATH = Path(\"H:/SentimentAnalystSchool/MidtermExam/DatasetUnder80kWord/merged_all_final.csv\")\n",
    "df_all_combined.to_csv(OUTPUT_ALL_PATH, index=False)\n",
    "\n",
    "print(f\"‚úÖ ƒê√£ l∆∞u file g·ªôp: {OUTPUT_ALL_PATH}\")\n",
    "print(f\"   T·ªïng s·ªë d√≤ng: {len(df_all_combined):,}\")\n",
    "\n",
    "# Xem m·∫´u d·ªØ li·ªáu\n",
    "print(\"\\nüìã M·∫´u d·ªØ li·ªáu (10 d√≤ng ƒë·∫ßu):\")\n",
    "df_all_combined.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
