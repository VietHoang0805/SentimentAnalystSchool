{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7a4cef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C·∫•u h√¨nh ƒë∆∞·ªùng d·∫´n files:\n",
      "\n",
      "Amazon:\n",
      "  train: train_reviews_under80words.csv [‚úì]\n",
      "  dev: dev_reviews_under80words.csv [‚úì]\n",
      "  test: test_reviews_under80words.csv [‚úì]\n",
      "\n",
      "Hotels:\n",
      "  train: train_reviews_under80words.csv [‚úì]\n",
      "  dev: dev_reviews_under80words.csv [‚úì]\n",
      "  test: test_reviews_under80words.csv [‚úì]\n",
      "\n",
      "AmazonsElectronics:\n",
      "  all: neutral_output_aspect.csv [‚úì]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n g·ªëc\n",
    "BASE_PATH = Path(\"H:/SentimentAnalystSchool/MidtermExam/DatasetUnder80kWord\")\n",
    "\n",
    "# ƒê·ªãnh nghƒ©a c√°c file c·∫ßn g·ªôp\n",
    "FILES_CONFIG = {\n",
    "    \"Amazon\": {\n",
    "        \"train\": BASE_PATH / \"Amazon\" / \"train_reviews_under80words.csv\",\n",
    "        \"dev\": BASE_PATH / \"Amazon\" / \"dev_reviews_under80words.csv\",\n",
    "        \"test\": BASE_PATH / \"Amazon\" / \"test_reviews_under80words.csv\"\n",
    "    },\n",
    "    \"Hotels\": {\n",
    "        \"train\": BASE_PATH / \"Hotels\" / \"train_reviews_under80words.csv\",\n",
    "        \"dev\": BASE_PATH / \"Hotels\" / \"dev_reviews_under80words.csv\",\n",
    "        \"test\": BASE_PATH / \"Hotels\" / \"test_reviews_under80words.csv\"\n",
    "    },\n",
    "    \"AmazonsElectronics\": {\n",
    "        \"all\": BASE_PATH / \"AmazonsElectronics\" / \"Kaggle\" / \"neutral_output_aspect.csv\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"C·∫•u h√¨nh ƒë∆∞·ªùng d·∫´n files:\")\n",
    "for source, files in FILES_CONFIG.items():\n",
    "    print(f\"\\n{source}:\")\n",
    "    for file_type, path in files.items():\n",
    "        exists = \"‚úì\" if path.exists() else \"‚úó\"\n",
    "        print(f\"  {file_type}: {path.name} [{exists}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c5acd404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H√†m load_and_standardize_data ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a!\n"
     ]
    }
   ],
   "source": [
    "def load_and_standardize_data(file_path):\n",
    "    \"\"\"\n",
    "    ƒê·ªçc file CSV v√† chu·∫©n h√≥a c·ªôt th√†nh reviewText, AspectTerm, Sentiment\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path: ƒë∆∞·ªùng d·∫´n file\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame ƒë√£ chu·∫©n h√≥a v·ªõi 3 c·ªôt: reviewText, AspectTerm, Sentiment\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Chu·∫©n h√≥a t√™n c·ªôt th√†nh ch·ªØ th∆∞·ªùng ƒë·ªÉ d·ªÖ x·ª≠ l√Ω\n",
    "        df.columns = df.columns.str.strip().str.lower()\n",
    "        \n",
    "        # Map c√°c t√™n c·ªôt c√≥ th·ªÉ kh√°c nhau v·ªÅ t√™n chu·∫©n\n",
    "        column_mapping = {\n",
    "            'reviewtext': 'reviewText',\n",
    "            'review': 'reviewText',\n",
    "            'text': 'reviewText',\n",
    "            'aspectterm': 'AspectTerm',\n",
    "            'aspect': 'AspectTerm',\n",
    "            'sentiment': 'Sentiment'\n",
    "        }\n",
    "        \n",
    "        df = df.rename(columns=column_mapping)\n",
    "        \n",
    "        # Ch·ªâ gi·ªØ 3 c·ªôt c·∫ßn thi·∫øt\n",
    "        required_cols = ['reviewText', 'AspectTerm', 'Sentiment']\n",
    "        available_cols = [col for col in required_cols if col in df.columns]\n",
    "        df = df[available_cols]\n",
    "        \n",
    "        # Drop c√°c d√≤ng c√≥ AspectTerm tr·ªëng ho·∫∑c null\n",
    "        rows_before = len(df)\n",
    "        if 'AspectTerm' in df.columns:\n",
    "            df = df.dropna(subset=['AspectTerm'])\n",
    "            df = df[df['AspectTerm'].str.strip() != '']\n",
    "            df = df[df['AspectTerm'].str.lower() != 'none']\n",
    "        rows_after = len(df)\n",
    "        dropped = rows_before - rows_after\n",
    "        \n",
    "        print(f\"  ‚úì Loaded {rows_after} rows from {file_path.name} (dropped {dropped} rows with empty AspectTerm)\")\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚úó Error loading {file_path}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "print(\"H√†m load_and_standardize_data ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab62276e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H√†m merge_all_datasets ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a!\n"
     ]
    }
   ],
   "source": [
    "def merge_all_datasets(files_config, output_path=None, balance_config=None):\n",
    "    \"\"\"\n",
    "    G·ªôp t·∫•t c·∫£ c√°c dataset th√†nh m·ªôt file duy nh·∫•t\n",
    "    \n",
    "    Parameters:\n",
    "    - files_config: dict ch·ª©a c·∫•u h√¨nh c√°c file\n",
    "    - output_path: ƒë∆∞·ªùng d·∫´n l∆∞u file output (optional)\n",
    "    - balance_config: dict ƒë·ªÉ gi·ªõi h·∫°n s·ªë l∆∞·ª£ng m·∫´u theo sentiment (optional)\n",
    "                      V√≠ d·ª•: {'positive': 5000, 'negative': 5000, 'neutral': 5000}\n",
    "                      N·∫øu None, gi·ªØ nguy√™n t·∫•t c·∫£ d·ªØ li·ªáu\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame ƒë√£ g·ªôp v·ªõi 3 c·ªôt: reviewText, AspectTerm, Sentiment\n",
    "    \"\"\"\n",
    "    all_dataframes = []\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"B·∫ÆT ƒê·∫¶U G·ªòP DATASETS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for source_name, files in files_config.items():\n",
    "        print(f\"\\nüìÇ Loading from {source_name}:\")\n",
    "        for file_type, file_path in files.items():\n",
    "            if file_path.exists():\n",
    "                df = load_and_standardize_data(file_path)\n",
    "                if not df.empty:\n",
    "                    all_dataframes.append(df)\n",
    "            else:\n",
    "                print(f\"  ‚ö† File not found: {file_path}\")\n",
    "    \n",
    "    if not all_dataframes:\n",
    "        print(\"\\n‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu n√†o ƒë∆∞·ª£c load!\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # G·ªôp t·∫•t c·∫£\n",
    "    merged_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"K·∫æT QU·∫¢ G·ªòP DATASET (TR∆Ø·ªöC KHI C√ÇN B·∫∞NG)\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\nüìä T·ªïng s·ªë m·∫´u: {len(merged_df):,}\")\n",
    "    print(f\"\\nüìà Ph√¢n b·ªë theo Sentiment:\")\n",
    "    print(merged_df['Sentiment'].value_counts().to_string())\n",
    "    \n",
    "    # √Åp d·ª•ng balance_config n·∫øu c√≥\n",
    "    if balance_config:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"√ÅP D·ª§NG C√ÇN B·∫∞NG D·ªÆ LI·ªÜU\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        balanced_dfs = []\n",
    "        for sentiment, max_count in balance_config.items():\n",
    "            sentiment_df = merged_df[merged_df['Sentiment'].str.lower() == sentiment.lower()]\n",
    "            current_count = len(sentiment_df)\n",
    "            \n",
    "            if current_count > max_count:\n",
    "                sentiment_df = sentiment_df.sample(n=max_count, random_state=42)\n",
    "                print(f\"  {sentiment}: {current_count:,} ‚Üí {max_count:,} (gi·∫£m {current_count - max_count:,})\")\n",
    "            else:\n",
    "                print(f\"  {sentiment}: {current_count:,} (gi·ªØ nguy√™n, √≠t h∆°n {max_count:,})\")\n",
    "            \n",
    "            balanced_dfs.append(sentiment_df)\n",
    "        \n",
    "        merged_df = pd.concat(balanced_dfs, ignore_index=True)\n",
    "        merged_df = merged_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"K·∫æT QU·∫¢ CU·ªêI C√ôNG\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\nüìä T·ªïng s·ªë m·∫´u: {len(merged_df):,}\")\n",
    "    print(f\"\\nüìà Ph√¢n b·ªë theo Sentiment:\")\n",
    "    print(merged_df['Sentiment'].value_counts().to_string())\n",
    "    print(f\"\\nüìã C√°c c·ªôt: {list(merged_df.columns)}\")\n",
    "    \n",
    "    # L∆∞u file n·∫øu c√≥ output_path\n",
    "    if output_path:\n",
    "        merged_df.to_csv(output_path, index=False)\n",
    "        print(f\"\\nüíæ ƒê√£ l∆∞u file: {output_path}\")\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "print(\"H√†m merge_all_datasets ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "240f011c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "B·∫ÆT ƒê·∫¶U G·ªòP DATASETS\n",
      "============================================================\n",
      "\n",
      "üìÇ Loading from Amazon:\n",
      "  ‚úì Loaded 6297 rows from train_reviews_under80words.csv (dropped 0 rows with empty AspectTerm)\n",
      "  ‚úì Loaded 974 rows from dev_reviews_under80words.csv (dropped 0 rows with empty AspectTerm)\n",
      "  ‚úì Loaded 966 rows from test_reviews_under80words.csv (dropped 0 rows with empty AspectTerm)\n",
      "\n",
      "üìÇ Loading from Hotels:\n",
      "  ‚úì Loaded 10126 rows from train_reviews_under80words.csv (dropped 0 rows with empty AspectTerm)\n",
      "  ‚úì Loaded 1036 rows from dev_reviews_under80words.csv (dropped 0 rows with empty AspectTerm)\n",
      "  ‚úì Loaded 242 rows from test_reviews_under80words.csv (dropped 0 rows with empty AspectTerm)\n",
      "\n",
      "üìÇ Loading from AmazonsElectronics:\n",
      "  ‚úì Loaded 1212 rows from neutral_output_aspect.csv (dropped 3788 rows with empty AspectTerm)\n",
      "\n",
      "============================================================\n",
      "K·∫æT QU·∫¢ G·ªòP DATASET (TR∆Ø·ªöC KHI C√ÇN B·∫∞NG)\n",
      "============================================================\n",
      "\n",
      "üìä T·ªïng s·ªë m·∫´u: 20,853\n",
      "\n",
      "üìà Ph√¢n b·ªë theo Sentiment:\n",
      "Sentiment\n",
      "positive    15937\n",
      "negative     3116\n",
      "neutral      1788\n",
      "\n",
      "============================================================\n",
      "√ÅP D·ª§NG C√ÇN B·∫∞NG D·ªÆ LI·ªÜU\n",
      "============================================================\n",
      "  positive: 15,937 ‚Üí 3,000 (gi·∫£m 12,937)\n",
      "  negative: 3,116 ‚Üí 3,000 (gi·∫£m 116)\n",
      "  neutral: 1,788 (gi·ªØ nguy√™n, √≠t h∆°n 1,788)\n",
      "\n",
      "============================================================\n",
      "K·∫æT QU·∫¢ CU·ªêI C√ôNG\n",
      "============================================================\n",
      "\n",
      "üìä T·ªïng s·ªë m·∫´u: 7,788\n",
      "\n",
      "üìà Ph√¢n b·ªë theo Sentiment:\n",
      "Sentiment\n",
      "positive    3000\n",
      "negative    3000\n",
      "neutral     1788\n",
      "\n",
      "üìã C√°c c·ªôt: ['reviewText', 'AspectTerm', 'Sentiment']\n",
      "\n",
      "üíæ ƒê√£ l∆∞u file: H:\\SentimentAnalystSchool\\MidtermExam\\DatasetUnder80kWord\\merged_dataset_all_7700rows.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# C·∫§U H√åNH S·ªê L∆Ø·ª¢NG M·∫™U THEO SENTIMENT\n",
    "# ============================================\n",
    "# Ch·ªânh s·ª≠a c√°c gi√° tr·ªã b√™n d∆∞·ªõi ƒë·ªÉ thay ƒë·ªïi s·ªë l∆∞·ª£ng m·∫´u cho m·ªói nh√£n\n",
    "# ƒê·∫∑t None n·∫øu mu·ªën gi·ªØ t·∫•t c·∫£ d·ªØ li·ªáu kh√¥ng gi·ªõi h·∫°n\n",
    "\n",
    "BALANCE_CONFIG = {\n",
    "    'positive': 3000,   # S·ªë l∆∞·ª£ng m·∫´u positive t·ªëi ƒëa\n",
    "    'negative': 3000,   # S·ªë l∆∞·ª£ng m·∫´u negative t·ªëi ƒëa  \n",
    "    'neutral': 1788    # S·ªë l∆∞·ª£ng m·∫´u neutral t·ªëi ƒëa\n",
    "}\n",
    "\n",
    "# ƒê·∫∑t BALANCE_CONFIG = None n·∫øu mu·ªën gi·ªØ t·∫•t c·∫£ d·ªØ li·ªáu\n",
    "# BALANCE_CONFIG = None\n",
    "\n",
    "# ============================================\n",
    "# Th·ª±c hi·ªán g·ªôp dataset\n",
    "OUTPUT_PATH = BASE_PATH / \"merged_dataset_all_7700rows.csv\"\n",
    "\n",
    "merged_df = merge_all_datasets(\n",
    "    FILES_CONFIG, \n",
    "    output_path=OUTPUT_PATH,\n",
    "    balance_config=BALANCE_CONFIG\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f236f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã M·ªôt s·ªë m·∫´u d·ªØ li·ªáu ƒë·∫ßu ti√™n:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>AspectTerm</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>While the tablet is nice, and well constructed...</td>\n",
       "      <td>google play</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Highly recommended for those looking for that ...</td>\n",
       "      <td>food recommendation</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZICO Pure Premium Coconut Water , Natural , 11...</td>\n",
       "      <td>food general</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is the only time I have strongly disliked...</td>\n",
       "      <td>food quality</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Located on Via Della Scala , it was the perfec...</td>\n",
       "      <td>location general</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>It works in some, not all USB ports because it...</td>\n",
       "      <td>installation</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I LOVE PB , but try not to eat too much becaus...</td>\n",
       "      <td>food general</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Excellent Booked this hotel a couple of months...</td>\n",
       "      <td>hotel general</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>McCormick spices aren ' t exactly world - reno...</td>\n",
       "      <td>food general</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>First thing , the room was really small and sq...</td>\n",
       "      <td>rooms design_features</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText             AspectTerm  \\\n",
       "0  While the tablet is nice, and well constructed...            google play   \n",
       "1  Highly recommended for those looking for that ...    food recommendation   \n",
       "2  ZICO Pure Premium Coconut Water , Natural , 11...           food general   \n",
       "3  This is the only time I have strongly disliked...           food quality   \n",
       "4  Located on Via Della Scala , it was the perfec...       location general   \n",
       "5  It works in some, not all USB ports because it...           installation   \n",
       "6  I LOVE PB , but try not to eat too much becaus...           food general   \n",
       "7  Excellent Booked this hotel a couple of months...          hotel general   \n",
       "8  McCormick spices aren ' t exactly world - reno...           food general   \n",
       "9  First thing , the room was really small and sq...  rooms design_features   \n",
       "\n",
       "  Sentiment  \n",
       "0   neutral  \n",
       "1  positive  \n",
       "2  positive  \n",
       "3  negative  \n",
       "4  positive  \n",
       "5   neutral  \n",
       "6   neutral  \n",
       "7  positive  \n",
       "8   neutral  \n",
       "9  negative  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Xem m·ªôt s·ªë m·∫´u d·ªØ li·ªáu\n",
    "print(\"üìã M·ªôt s·ªë m·∫´u d·ªØ li·ªáu ƒë·∫ßu ti√™n:\")\n",
    "merged_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86322249",
   "metadata": {},
   "source": [
    "## T·ªïng k·∫øt\n",
    "\n",
    "File ƒë√£ ƒë∆∞·ª£c t·∫°o v·ªõi c·∫•u tr√∫c 3 c·ªôt:\n",
    "- `reviewText`: N·ªôi dung review\n",
    "- `AspectTerm`: Aspect term ƒë∆∞·ª£c tr√≠ch xu·∫•t\n",
    "- `Sentiment`: Nh√£n sentiment (positive/negative/neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea78927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
