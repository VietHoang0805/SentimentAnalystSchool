{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e09199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "# ÄÆ°á»ng dáº«n Ä‘áº¿n thÆ° má»¥c Dataset\n",
    "dataset_path = Path('Dataset')\n",
    "en_path = dataset_path / 'en'\n",
    "es_path = dataset_path / 'es'\n",
    "\n",
    "# Äá»‹nh nghÄ©a cÃ¡c category\n",
    "categories = ['News', 'Others', 'Reviews', 'Social Media']\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"Äá»ŒC Dá»® LIá»†U Tá»ª CÃC FOLDER VÃ€ CATEGORY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Danh sÃ¡ch Ä‘á»ƒ lÆ°u trá»¯ táº¥t cáº£ dataframes\n",
    "all_dfs = []\n",
    "\n",
    "# Äá»c dá»¯ liá»‡u tá»« tiáº¿ng Anh\n",
    "print(\"\\nğŸ‡¬ğŸ‡§ Tiáº¿ng Anh (EN):\")\n",
    "for category in categories:\n",
    "    category_path = en_path / category\n",
    "    if category_path.exists():\n",
    "        files = glob.glob(str(category_path / '*.tsv'))\n",
    "        print(f\"\\n  ğŸ“ Category: {category}\")\n",
    "        print(f\"     TÃ¬m tháº¥y {len(files)} files\")\n",
    "        \n",
    "        for file in files:\n",
    "            try:\n",
    "                df = pd.read_csv(file, sep='\\t', header=None, names=['sentiment', 'text', 'score'])\n",
    "                df['language'] = 'en'\n",
    "                df['category'] = category\n",
    "                df['source'] = os.path.basename(file).replace('.tsv', '')\n",
    "                all_dfs.append(df)\n",
    "                print(f\"     âœ“ {os.path.basename(file)}: {len(df):,} dÃ²ng\")\n",
    "            except Exception as e:\n",
    "                print(f\"     âœ— Lá»—i khi Ä‘á»c {file}: {e}\")\n",
    "\n",
    "# Äá»c dá»¯ liá»‡u tá»« tiáº¿ng TÃ¢y Ban Nha\n",
    "print(\"\\nğŸ‡ªğŸ‡¸ Tiáº¿ng TÃ¢y Ban Nha (ES):\")\n",
    "for category in categories:\n",
    "    category_path = es_path / category\n",
    "    if category_path.exists():\n",
    "        files = glob.glob(str(category_path / '*.tsv'))\n",
    "        print(f\"\\n  ğŸ“ Category: {category}\")\n",
    "        print(f\"     TÃ¬m tháº¥y {len(files)} files\")\n",
    "        \n",
    "        for file in files:\n",
    "            try:\n",
    "                df = pd.read_csv(file, sep='\\t', header=None, names=['sentiment', 'text', 'score'])\n",
    "                df['language'] = 'es'\n",
    "                df['category'] = category\n",
    "                df['source'] = os.path.basename(file).replace('.tsv', '')\n",
    "                all_dfs.append(df)\n",
    "                print(f\"     âœ“ {os.path.basename(file)}: {len(df):,} dÃ²ng\")\n",
    "            except Exception as e:\n",
    "                print(f\"     âœ— Lá»—i khi Ä‘á»c {file}: {e}\")\n",
    "\n",
    "# Gá»™p táº¥t cáº£ dá»¯ liá»‡u\n",
    "combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"THá»NG KÃŠ Dá»® LIá»†U BAN Äáº¦U\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Tá»•ng sá»‘ dÃ²ng: {len(combined_df):,}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š PhÃ¢n bá»‘ theo NgÃ´n ngá»¯:\")\n",
    "for lang, count in combined_df['language'].value_counts().items():\n",
    "    lang_name = 'English' if lang == 'en' else 'Spanish'\n",
    "    print(f\"   {lang_name} ({lang}): {count:,}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š PhÃ¢n bá»‘ theo Category:\")\n",
    "for cat, count in combined_df['category'].value_counts().items():\n",
    "    print(f\"   {cat}: {count:,}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š PhÃ¢n bá»‘ theo Sentiment:\")\n",
    "for sent, count in combined_df['sentiment'].value_counts().sort_index().items():\n",
    "    sent_name = 'Negative' if sent == -1 else ('Neutral' if sent == 0 else 'Positive')\n",
    "    print(f\"   {sent_name} ({sent}): {count:,}\")\n",
    "\n",
    "# Hiá»ƒn thá»‹ phÃ¢n bá»‘ chi tiáº¿t\n",
    "print(f\"\\nğŸ“Š PhÃ¢n bá»‘ Language x Category:\")\n",
    "print(pd.crosstab(combined_df['language'], combined_df['category']))\n",
    "\n",
    "print(f\"\\nğŸ“Š PhÃ¢n bá»‘ Language x Sentiment:\")\n",
    "print(pd.crosstab(combined_df['language'], combined_df['sentiment']))\n",
    "\n",
    "print(f\"\\nğŸ“Š PhÃ¢n bá»‘ Category x Sentiment:\")\n",
    "print(pd.crosstab(combined_df['category'], combined_df['sentiment']))\n",
    "\n",
    "# ==================================================\n",
    "# CÃ‚N Báº°NG Dá»® LIá»†U THEO 3 CHIá»€U\n",
    "# ==================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CÃ‚N Báº°NG Dá»® LIá»†U THEO NGÃ”N NGá»®, CATEGORY VÃ€ SENTIMENT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# TÃ­nh sá»‘ lÆ°á»£ng máº«u cho má»—i tá»• há»£p (language, category, sentiment)\n",
    "group_counts = combined_df.groupby(['language', 'category', 'sentiment']).size()\n",
    "print(\"\\nSá»‘ lÆ°á»£ng máº«u cho má»—i tá»• há»£p (Language x Category x Sentiment):\")\n",
    "print(group_counts.sort_index())\n",
    "\n",
    "# TÃ¬m sá»‘ lÆ°á»£ng nhá» nháº¥t\n",
    "min_samples_per_group = group_counts.min()\n",
    "print(f\"\\nğŸ¯ Sá»‘ lÆ°á»£ng máº«u nhá» nháº¥t trong cÃ¡c tá»• há»£p: {min_samples_per_group:,}\")\n",
    "\n",
    "# Äáº·t target cho má»—i tá»• há»£p (cÃ³ thá»ƒ Ä‘iá»u chá»‰nh)\n",
    "target_per_group = min(min_samples_per_group, 1000)  # Giá»›i háº¡n tá»‘i Ä‘a 1000 máº«u/tá»• há»£p\n",
    "print(f\"ğŸ“Œ Sáº½ láº¥y {target_per_group:,} máº«u cho má»—i tá»• há»£p\")\n",
    "\n",
    "# Láº¥y máº«u cÃ¢n báº±ng\n",
    "balanced_dfs = []\n",
    "summary_data = []\n",
    "\n",
    "for language in ['en', 'es']:\n",
    "    for category in categories:\n",
    "        for sentiment in [-1, 0, 1]:\n",
    "            # Lá»c dá»¯ liá»‡u cho tá»• há»£p hiá»‡n táº¡i\n",
    "            mask = (combined_df['language'] == language) & \\\n",
    "                   (combined_df['category'] == category) & \\\n",
    "                   (combined_df['sentiment'] == sentiment)\n",
    "            group_df = combined_df[mask]\n",
    "            \n",
    "            if len(group_df) > 0:\n",
    "                # Láº¥y máº«u\n",
    "                n_samples = min(len(group_df), target_per_group)\n",
    "                if len(group_df) >= target_per_group:\n",
    "                    sampled = group_df.sample(n=target_per_group, random_state=42)\n",
    "                else:\n",
    "                    sampled = group_df\n",
    "                \n",
    "                balanced_dfs.append(sampled)\n",
    "                \n",
    "                lang_name = 'EN' if language == 'en' else 'ES'\n",
    "                sent_name = 'Neg' if sentiment == -1 else ('Neu' if sentiment == 0 else 'Pos')\n",
    "                summary_data.append({\n",
    "                    'Language': lang_name,\n",
    "                    'Category': category,\n",
    "                    'Sentiment': sent_name,\n",
    "                    'Original': len(group_df),\n",
    "                    'Sampled': n_samples\n",
    "                })\n",
    "\n",
    "# Táº¡o summary DataFrame\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(\"\\nğŸ“‹ TÃ³m táº¯t quÃ¡ trÃ¬nh láº¥y máº«u:\")\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Gá»™p táº¥t cáº£ cÃ¡c máº«u Ä‘Ã£ cÃ¢n báº±ng\n",
    "final_df = pd.concat(balanced_dfs, ignore_index=True)\n",
    "\n",
    "# Trá»™n ngáº«u nhiÃªn\n",
    "final_df = final_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Sáº¯p xáº¿p láº¡i thá»© tá»± cÃ¡c cá»™t\n",
    "final_df = final_df[['text', 'sentiment', 'score', 'language', 'category', 'source']]\n",
    "\n",
    "# ==================================================\n",
    "# HIá»‚N THá»Š THÃ”NG TIN CUá»I CÃ™NG\n",
    "# ==================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"THÃ”NG TIN DATASET SAU KHI CÃ‚N Báº°NG\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Tá»•ng sá»‘ dÃ²ng: {len(final_df):,}\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ CÃ¡c cá»™t: {final_df.columns.tolist()}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š PhÃ¢n bá»‘ NgÃ´n ngá»¯ (cÃ¢n báº±ng):\")\n",
    "for lang, count in final_df['language'].value_counts().items():\n",
    "    lang_name = 'English' if lang == 'en' else 'Spanish'\n",
    "    print(f\"   {lang_name} ({lang}): {count:,} ({count/len(final_df)*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nğŸ“Š PhÃ¢n bá»‘ Category (cÃ¢n báº±ng):\")\n",
    "for cat, count in final_df['category'].value_counts().items():\n",
    "    print(f\"   {cat}: {count:,} ({count/len(final_df)*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nğŸ“Š PhÃ¢n bá»‘ Sentiment (cÃ¢n báº±ng):\")\n",
    "for sent, count in final_df['sentiment'].value_counts().sort_index().items():\n",
    "    sent_name = 'Negative' if sent == -1 else ('Neutral' if sent == 0 else 'Positive')\n",
    "    print(f\"   {sent_name} ({sent}): {count:,} ({count/len(final_df)*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Crosstab: Language x Category\")\n",
    "print(pd.crosstab(final_df['language'], final_df['category'], margins=True))\n",
    "\n",
    "print(f\"\\nğŸ“Š Crosstab: Language x Sentiment\")\n",
    "print(pd.crosstab(final_df['language'], final_df['sentiment'], margins=True))\n",
    "\n",
    "print(f\"\\nğŸ“Š Crosstab: Category x Sentiment\")\n",
    "print(pd.crosstab(final_df['category'], final_df['sentiment'], margins=True))\n",
    "\n",
    "print(f\"\\nğŸ“Š Crosstab 3D: Sá»‘ lÆ°á»£ng cho má»—i tá»• há»£p\")\n",
    "group_final = final_df.groupby(['language', 'category', 'sentiment']).size()\n",
    "print(group_final.unstack(fill_value=0))\n",
    "\n",
    "print(f\"\\nğŸ” Máº«u dá»¯ liá»‡u:\")\n",
    "final_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9994a7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiá»ƒm tra cáº¥u trÃºc trÆ°á»›c khi lÆ°u\n",
    "print(\"=\"*80)\n",
    "print(\"KIá»‚M TRA CHáº¤T LÆ¯á»¢NG Dá»® LIá»†U\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Shape: {final_df.shape}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Kiá»ƒu dá»¯ liá»‡u cÃ¡c cá»™t:\")\n",
    "print(final_df.dtypes)\n",
    "\n",
    "print(f\"\\nâ“ Kiá»ƒm tra missing values:\")\n",
    "missing_count = final_df.isnull().sum()\n",
    "print(missing_count)\n",
    "if missing_count.sum() == 0:\n",
    "    print(\"âœ… KhÃ´ng cÃ³ giÃ¡ trá»‹ thiáº¿u!\")\n",
    "\n",
    "print(f\"\\nğŸ”„ Kiá»ƒm tra duplicate:\")\n",
    "dup_count = final_df.duplicated().sum()\n",
    "print(f\"Sá»‘ dÃ²ng trÃ¹ng láº·p: {dup_count}\")\n",
    "\n",
    "print(f\"\\nâš–ï¸ Kiá»ƒm tra cÃ¢n báº±ng - NgÃ´n ngá»¯:\")\n",
    "print(final_df['language'].value_counts())\n",
    "\n",
    "print(f\"\\nâš–ï¸ Kiá»ƒm tra cÃ¢n báº±ng - Category:\")\n",
    "print(final_df['category'].value_counts())\n",
    "\n",
    "print(f\"\\nâš–ï¸ Kiá»ƒm tra cÃ¢n báº±ng - Sentiment:\")\n",
    "print(final_df['sentiment'].value_counts().sort_index())\n",
    "\n",
    "# Kiá»ƒm tra cÃ¢n báº±ng tá»•ng thá»ƒ\n",
    "print(f\"\\nâš–ï¸ Kiá»ƒm tra cÃ¢n báº±ng tá»•ng thá»ƒ (Language x Category x Sentiment):\")\n",
    "balance_check = final_df.groupby(['language', 'category', 'sentiment']).size()\n",
    "print(f\"Sá»‘ lÆ°á»£ng unique values: {balance_check.unique()}\")\n",
    "if len(balance_check.unique()) == 1:\n",
    "    print(f\"âœ… Dataset hoÃ n toÃ n cÃ¢n báº±ng! Má»—i tá»• há»£p cÃ³ {balance_check.iloc[0]:,} máº«u\")\n",
    "else:\n",
    "    print(f\"âš ï¸ Dataset chÆ°a hoÃ n toÃ n cÃ¢n báº±ng:\")\n",
    "    print(f\"   Min: {balance_check.min():,}\")\n",
    "    print(f\"   Max: {balance_check.max():,}\")\n",
    "    print(f\"   Mean: {balance_check.mean():.2f}\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ 10 dÃ²ng máº«u:\")\n",
    "print(final_df.head(10))\n",
    "\n",
    "# LÆ°u dataset vÃ o file CSV\n",
    "output_file = 'Dataset/balanced_multilingual_multicategory_dataset.csv'\n",
    "final_df.to_csv(output_file, index=False, encoding='utf-8-sig', sep=',')\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… ÄÃƒ LÆ¯U DATASET THÃ€NH CÃ”NG!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"ğŸ“ File: {output_file}\")\n",
    "print(f\"ğŸ“Š Sá»‘ lÆ°á»£ng dÃ²ng: {len(final_df):,}\")\n",
    "print(f\"ğŸ“‹ CÃ¡c cá»™t: {', '.join(final_df.columns)}\")\n",
    "print(f\"\\nâœ… Dataset Ä‘Ã£ Ä‘Æ°á»£c cÃ¢n báº±ng hoÃ n toÃ n:\")\n",
    "print(f\"   ğŸŒ NgÃ´n ngá»¯: English (EN) vs Spanish (ES)\")\n",
    "print(f\"   ğŸ“ Category: {', '.join(final_df['category'].unique())}\")\n",
    "print(f\"   ğŸ˜Š Sentiment: Negative vs Neutral vs Positive\")\n",
    "print(f\"\\nğŸ¯ Má»—i tá»• há»£p (Language x Category x Sentiment) cÃ³ sá»‘ lÆ°á»£ng máº«u báº±ng nhau\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Hiá»ƒn thá»‹ phÃ¢n bá»‘ chi tiáº¿t cuá»‘i cÃ¹ng\n",
    "print(f\"\\nğŸ“Š PHÃ‚N Bá» CHI TIáº¾T CUá»I CÃ™NG\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1ï¸âƒ£ Language x Category:\")\n",
    "ct1 = pd.crosstab(final_df['language'], final_df['category'], margins=True)\n",
    "print(ct1)\n",
    "\n",
    "print(\"\\n2ï¸âƒ£ Language x Sentiment:\")\n",
    "ct2 = pd.crosstab(final_df['language'], final_df['sentiment'], margins=True)\n",
    "print(ct2)\n",
    "\n",
    "print(\"\\n3ï¸âƒ£ Category x Sentiment:\")\n",
    "ct3 = pd.crosstab(final_df['category'], final_df['sentiment'], margins=True)\n",
    "print(ct3)\n",
    "\n",
    "print(\"\\n4ï¸âƒ£ PhÃ¢n bá»‘ 3 chiá»u (Language x Category x Sentiment):\")\n",
    "for lang in final_df['language'].unique():\n",
    "    lang_name = 'English (EN)' if lang == 'en' else 'Spanish (ES)'\n",
    "    print(f\"\\n   {lang_name}:\")\n",
    "    lang_data = final_df[final_df['language'] == lang]\n",
    "    ct = pd.crosstab(lang_data['category'], lang_data['sentiment'])\n",
    "    print(ct)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
